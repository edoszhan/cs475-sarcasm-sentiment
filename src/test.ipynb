{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111635/1451095612.py:6: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  comments_df = pd.read_csv('../datasets/university_comments.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number                                            comment  label\n",
      "0    6252           [id82234233|Фарида], верно подмечено 😌👍🏻      0\n",
      "1    4684  Обычно бухгалтера занимаются сВеркой и сВодко...      1\n",
      "2    1731  Из школьного сочинения:Суворов был настоящим м...      1\n",
      "3    4742  Василиса - Прекрасная после ночи с Иванушкой ...      1\n",
      "4    4521  Русский человек даже обыкновенный гвоздь заб...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111635/1451095612.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_sentence_jokes['label'] = 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# For clarification: cleaned_combined_comments are labeled by our team\n",
    "\n",
    "# Load the datasets (note: both datasets may contain offensive language since this is public data)\n",
    "jokes_df = pd.read_csv('../datasets/jokes.csv')\n",
    "comments_df = pd.read_csv('../datasets/university_comments.csv')\n",
    "\n",
    "# Define a function to identify one-sentence jokes for normalization\n",
    "def normalize_sentence(text):\n",
    "    # Count the number of sentence-ending punctuation marks\n",
    "    sentences = re.split(r'[.!?]', text)  \n",
    "\n",
    "    sentences = [s for s in sentences if s.strip() != '']\n",
    "    return len(sentences) == 1\n",
    "\n",
    "# Filter jokes to keep only one-sentence jokes\n",
    "one_sentence_jokes = jokes_df[jokes_df['text'].apply(normalize_sentence)]\n",
    "one_sentence_jokes['label'] = 1\n",
    "\n",
    "# Select 2,500 one-sentence jokes\n",
    "jokes_sample = one_sentence_jokes.sample(n=5000, random_state=42)\n",
    "jokes_sample = jokes_sample[['text', 'label']]\n",
    "\n",
    "# Rename 'text' to 'comment' to match the structure with university comments\n",
    "jokes_sample.rename(columns={'text': 'comment'}, inplace=True)\n",
    "\n",
    "# Extract 2,500 random entries from university_comments and label as non-sarcastic (0)\n",
    "comments_sample = comments_df.sample(n=5000, random_state=42)\n",
    "comments_sample['label'] = 0\n",
    "comments_sample = comments_sample[['comment', 'label']]\n",
    "\n",
    "# Combine both datasets\n",
    "combined_data = pd.concat([jokes_sample, comments_sample], ignore_index=True)\n",
    "\n",
    "# Add a column for numbering (0 to 4999)\n",
    "combined_data.reset_index(inplace=True)\n",
    "combined_data.rename(columns={'index': 'number'}, inplace=True)\n",
    "\n",
    "# Shuffle the combined data\n",
    "df = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save dataset\n",
    "df.to_csv('../datasets/combined_comment.csv', index=False)\n",
    "\n",
    "# Verify the first few rows of the new dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number                                            comment  label\n",
      "0    6252                  id82234233фарида верно подмечено       0\n",
      "1    4684  обычно бухгалтера занимаются сверкои и сводкои...      1\n",
      "2    1731  из школьного сочинениясуворов был настоящим му...      1\n",
      "3    4742  василиса  прекрасная после ночи с иванушкои  д...      1\n",
      "4    4521  русскии человек даже обыкновенныи гвоздь забив...      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/cleaned_combined_comment.csv')\n",
    "\n",
    "import re # optional\n",
    "\n",
    "# Function to clean the text\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters, numbers, and lowercase the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Ensure all entries in the 'comment' column are strings and fill NaN values with empty strings\n",
    "df['comment'] = df['comment'].fillna('').astype(str)\n",
    "\n",
    "# Apply the preprocessing function to the 'comment' column\n",
    "df['comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number', 'comment', 'label'], dtype='object')\n",
      "Training set size: 5816\n",
      "Test set size: 2493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Display the column names to verify the label column\n",
    "print(df.columns)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df['comment']  # text data\n",
    "y = df['label']  # Our labels (0 or 1)\n",
    "\n",
    "# Split into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Show the size of the training and test sets\n",
    "print(f'Training set size: {len(X_train)}')\n",
    "print(f'Test set size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert the text data to numerical features (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      1013\n",
      "           1       0.87      0.81      0.84      1480\n",
      "\n",
      "    accuracy                           0.81      2493\n",
      "   macro avg       0.81      0.81      0.81      2493\n",
      "weighted avg       0.82      0.81      0.81      2493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_features, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_features)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/edoszhan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  label sentiment\n",
      "0                  id82234233фарида верно подмечено       0   neutral\n",
      "1  обычно бухгалтера занимаются сверкои и сводкои...      1   neutral\n",
      "2  из школьного сочинениясуворов был настоящим му...      1   neutral\n",
      "3  василиса  прекрасная после ночи с иванушкои  д...      1   neutral\n",
      "4  русскии человек даже обыкновенныи гвоздь забив...      1   neutral\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to determine sentiment (positive, neutral, or negative)\n",
    "def get_sentiment(comment):\n",
    "    score = sia.polarity_scores(comment)\n",
    "    if score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the sentiment analysis to the 'comment' column\n",
    "df['sentiment'] = df['comment'].apply(get_sentiment)\n",
    "\n",
    "# Show a sample of the data\n",
    "print(df[['comment', 'label', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment  negative  neutral  positive\n",
      "Sarcasm                               \n",
      "0                 5     3296         8\n",
      "1                16     4972        12\n",
      "Percentage breakdown of sarcastic comments by sentiment:\n",
      "Sentiment  negative    neutral  positive\n",
      "Sarcasm                                 \n",
      "0          0.151103  99.607132  0.241765\n",
      "1          0.320000  99.440000  0.240000\n"
     ]
    }
   ],
   "source": [
    "# Cross-tabulation of sarcasm vs. sentiment\n",
    "sarcasm_sentiment_stats = pd.crosstab(df['label'], df['sentiment'], rownames=['Sarcasm'], colnames=['Sentiment'])\n",
    "\n",
    "# Show statistics\n",
    "print(sarcasm_sentiment_stats)\n",
    "\n",
    "# Compute percentage breakdown\n",
    "sarcasm_sentiment_percent = sarcasm_sentiment_stats.div(sarcasm_sentiment_stats.sum(1), axis=0) * 100\n",
    "\n",
    "# Show percentage breakdown\n",
    "print(\"Percentage breakdown of sarcastic comments by sentiment:\")\n",
    "print(sarcasm_sentiment_percent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
